



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.0.1">
    
    
      
        <title>Mirror Maker 2.0 - Apache Kafka Studies</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.982221ab.css">
      
      
    
    
      <script src="../assets/javascripts/modernizr.1f0bcf2b.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../extra.css">
    
    
      
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#mirror-maker-20-studies" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="Apache Kafka Studies" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Apache Kafka Studies
            </span>
            <span class="md-header-nav__topic">
              Mirror Maker 2.0
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/jbcodeforce/kafka-studies.git/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href=".." title="Apache Kafka Studies" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Apache Kafka Studies
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/jbcodeforce/kafka-studies.git/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Introduction" class="md-nav__link">
      Introduction
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-eda/kafka/readme" title="Apache Kafka summary" class="md-nav__link">
      Apache Kafka summary
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-eda/kafka/consumers" title="Consumer practices" class="md-nav__link">
      Consumer practices
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-eda/kafka/producers" title="Producer practices" class="md-nav__link">
      Producer practices
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../kstreams/" title="Kafka streaming notes" class="md-nav__link">
      Kafka streaming notes
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Mirror Maker 2.0
      </label>
    
    <a href="./" title="Mirror Maker 2.0" class="md-nav__link md-nav__link--active">
      Mirror Maker 2.0
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pre-requisites" title="Pre-requisites" class="md-nav__link">
    Pre-requisites
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#general-concepts" title="General concepts" class="md-nav__link">
    General concepts
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-1-from-kafka-local-as-source-to-event-streams-on-cloud-as-target" title="Scenario 1: From Kafka local as source to Event Streams on Cloud as Target" class="md-nav__link">
    Scenario 1: From Kafka local as source to Event Streams on Cloud as Target
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-2-run-mirror-maker-2-cluster-close-to-target-cluster" title="Scenario 2: Run Mirror Maker 2 Cluster close to target cluster" class="md-nav__link">
    Scenario 2: Run Mirror Maker 2 Cluster close to target cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-3-from-event-streams-to-local-cluster" title="Scenario 3: From Event Streams to local cluster" class="md-nav__link">
    Scenario 3: From Event Streams to local cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-4-from-event-streams-on-cloud-to-strimzi-cluster-on-openshift" title="Scenario 4: From Event Streams On Cloud to Strimzi Cluster on Openshift" class="md-nav__link">
    Scenario 4: From Event Streams On Cloud to Strimzi Cluster on Openshift
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-5-from-kafka-cluster-on-openshift-cluster-to-local-cluster" title="Scenario 5: From Kafka cluster on Openshift cluster to local cluster" class="md-nav__link">
    Scenario 5: From Kafka cluster on Openshift cluster to local cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#typical-errors-in-mirror-maker-2-traces" title="Typical errors in Mirror Maker 2 traces" class="md-nav__link">
    Typical errors in Mirror Maker 2 traces
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-eda/kafka/FAQ" title="Kafka FAQ" class="md-nav__link">
      Kafka FAQ
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="https://ibm-cloud-architecture.github.io/refarch-eda/kafka/connect" title="Kafka Connect" class="md-nav__link">
      Kafka Connect
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pre-requisites" title="Pre-requisites" class="md-nav__link">
    Pre-requisites
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#general-concepts" title="General concepts" class="md-nav__link">
    General concepts
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-1-from-kafka-local-as-source-to-event-streams-on-cloud-as-target" title="Scenario 1: From Kafka local as source to Event Streams on Cloud as Target" class="md-nav__link">
    Scenario 1: From Kafka local as source to Event Streams on Cloud as Target
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-2-run-mirror-maker-2-cluster-close-to-target-cluster" title="Scenario 2: Run Mirror Maker 2 Cluster close to target cluster" class="md-nav__link">
    Scenario 2: Run Mirror Maker 2 Cluster close to target cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-3-from-event-streams-to-local-cluster" title="Scenario 3: From Event Streams to local cluster" class="md-nav__link">
    Scenario 3: From Event Streams to local cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-4-from-event-streams-on-cloud-to-strimzi-cluster-on-openshift" title="Scenario 4: From Event Streams On Cloud to Strimzi Cluster on Openshift" class="md-nav__link">
    Scenario 4: From Event Streams On Cloud to Strimzi Cluster on Openshift
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-5-from-kafka-cluster-on-openshift-cluster-to-local-cluster" title="Scenario 5: From Kafka cluster on Openshift cluster to local cluster" class="md-nav__link">
    Scenario 5: From Kafka cluster on Openshift cluster to local cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#typical-errors-in-mirror-maker-2-traces" title="Typical errors in Mirror Maker 2 traces" class="md-nav__link">
    Typical errors in Mirror Maker 2 traces
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/jbcodeforce/kafka-studies.git/edit/master/docs/mirrormaker.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="mirror-maker-20-studies">Mirror Maker 2.0 Studies</h1>
<p>Mirror Maker 2.0 is the new replication feature of Kafka 2.4. In this note we are presenting different test scenario for topic replication. </p>
<ul>
<li>Replicate from local cluster to Event Streams on Cloud (See detail <a href="#scenario-1-from-kafka-local-as-source-to-event-streams-on-cloud-as-target">in the scenario 1 section</a>)</li>
<li>Replicate from <a href="https://strimzi.io/">Strimzi</a> 'local' Kafka cluster running on OpenShift to Event Streams on Cloud. (See detail <a href="#scenario-2-run-mirror-maker-2-cluster-close-to-target-cluster">in the scenario 2 section</a>)</li>
<li>Replicate from <a href="#scenario-3-from-event-streams-to-local-cluster">Event Streams on cloud being the source cluster to local Kafka cluster</a> running on local machine (started via docker-compose) using Strimzi Kafka docker image.</li>
</ul>
<p>The <code>mirror-maker-2</code> folder includes, scripts, code and configurations to support the testing.</p>
<h2 id="pre-requisites">Pre-requisites</h2>
<ul>
<li>You need to have one Event Streams service on IBM Cloud.</li>
<li>We may need to use Event Streams CLI. So follow <a href="https://cloud.ibm.com/docs/services/EventStreams?topic=eventstreams-cli#cli">those instructions</a> to get it.</li>
</ul>
<p>The following command presents the Event Stream cluster metadata, like broker list and cluster ID:</p>
<div class="codehilite"><pre><span></span>ibmcloud es cluster
</pre></div>

<p>For other CLI commands see <a href="https://cloud.ibm.com/docs/services/EventStreams?topic=eventstreams-cli_reference">this summary</a>.</p>
<ul>
<li>To run local cluster we use docker-compose and docker. The docker compose file to start a local 3 Kafka brokers and 2 Zookeepers cluster is in <code>mirror-maker-2/local-cluster</code> folder. This compose file uses a local docker network called <code>kafkanet</code>. The docker image used for Kafka is coming from Strimzi open source project and is for the Kafka 2.4 version.</li>
<li>When the Event Streams service is created, add a service credentials and get the brokers list and api key information. We will use them in a setenv.sh script file under <code>mirror-maker-2</code> folder to define environment variables.</li>
</ul>
<h2 id="general-concepts">General concepts</h2>
<p>As <a href="https://strimzi.io/docs/master/#con-configuring-mirror-maker-deployment-configuration-kafka-mirror-maker">Mirror maker 2.0</a> is using kafka Connect framework, we recommend to review our summary <a href="https://ibm-cloud-architecture.github.io/refarch-eda/kafka/connect/">in this note</a>. </p>
<p>The figure below illustrates the mirror maker internal components running within Kafka Connect.</p>
<p><img alt="" src="../images/mm-k-connect.png" /></p>
<p>In distributed mode, Mirror Maker creates the following topics to the target cluster:</p>
<ul>
<li>mm2-configs.source.internal: This topic will store the connector and task configurations.</li>
<li>mm2-offsets.source.internal: This topic is used to store offsets for Kafka Connect.</li>
<li>mm2-status.source.internal: This topic will store status updates of connectors and tasks.</li>
<li>source.heartbeats</li>
<li>source.checkpoints.internal</li>
</ul>
<p>A typical mirror maker configuration is done via property file and define source and target cluster with their connection properties and the replication flow definitions. Here is a simple example</p>
<div class="codehilite"><pre><span></span><span class="na">clusters</span><span class="o">=</span><span class="s">source, target</span>
<span class="na">source.bootstrap.servers</span><span class="o">=</span><span class="s">${KAFKA_SOURCE_BROKERS}</span>
<span class="na">target.bootstrap.servers</span><span class="o">=</span><span class="s">${KAFKA_TARGET_BROKERS}</span>
<span class="na">target.security.protocol</span><span class="o">=</span><span class="s">SASL_SSL</span>
<span class="na">target.ssl.protocol</span><span class="o">=</span><span class="s">TLSv1.2</span>
<span class="na">target.ssl.endpoint.identification.algorithm</span><span class="o">=</span><span class="s">https</span>
<span class="na">target.sasl.mechanism</span><span class="o">=</span><span class="s">PLAIN</span>
<span class="na">target.sasl.jaas.config</span><span class="o">=</span><span class="s">org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;token&quot; password=${KAFKA_TARGET_APIKEY};</span>
<span class="c"># enable and configure individual replication flows</span>
<span class="na">source-&gt;target.enabled</span><span class="o">=</span><span class="s">true</span>
<span class="na">source-&gt;target.topics</span><span class="o">=</span><span class="s">products</span>
<span class="na">tasks.max</span><span class="o">=</span><span class="s">10</span>
</pre></div>

<ul>
<li>White listed topics are set with the <code>source-&gt;target.topics</code> attribute of the replication flow and use <a href="https://www.vogella.com/tutorials/JavaRegularExpressions/article.html">Java regular expression</a> syntax.</li>
<li>Blacklisted topics: by default the following pattern is applied:</li>
</ul>
<p><div class="codehilite"><pre><span></span><span class="na">blacklist</span> <span class="o">=</span> <span class="s">[follower\.replication\.throttled\.replicas, leader\.replication\.throttled\.replicas, message\.timestamp\.difference\.max\.ms, message\.timestamp\.type, unclean\.leader\.election\.enable, min\.insync\.replicas]</span>
</pre></div>
but can be also specified with the properties: <code>topics.blacklist</code>. Comma-separated lists are also supported.</p>
<p>Internally <code>MirrorSourceConnector</code> and <code>MirrorCheckpointConnector</code> will
create multiple tasks (up to tasks.max), <code>MirrorHeartbeatConnector</code>
creates only one single task. <code>MirrorSourceConnector</code> will have one task per topic-partition to replicate, while <code>MirrorCheckpointConnector</code> will have one task per consumer group. The Kafka connect framework uses the coordinator API, with assign API and so there is no consumer group while fetching data from source topic. There is no call to commit() neither: the rebalancing occurs only when there is a new topic created that matches the whitelist pattern.</p>
<h2 id="scenario-1-from-kafka-local-as-source-to-event-streams-on-cloud-as-target">Scenario 1: From Kafka local as source to Event Streams on Cloud as Target</h2>
<p>The scenario is to send the products definition in the local <code>products</code> topic and then start mirror maker to see the data replicated to the <code>source.products</code> topic in Event Streams cluster.</p>
<p><img alt="" src="../images/local-to-es.png" /></p>
<ul>
<li>Set the environment variables in setenv.sh to source broker is your local cluster, and the target is event streams with its API KEY</li>
</ul>
<div class="codehilite"><pre><span></span><span class="nb">export</span> <span class="nv">KAFKA_SOURCE_BROKERS</span><span class="o">=</span>kafka1:9092,kafka2:9093,kafka3:9094

<span class="nb">export</span> <span class="nv">KAFKA_TARGET_BROKERS</span><span class="o">=</span>broker-3-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-1-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-0-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-5-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-2-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-4-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093
<span class="nb">export</span> <span class="nv">KAFKA_TARGET_APIKEY</span><span class="o">=</span><span class="s2">&quot;&lt;password attribut in event streams credentials&gt;&quot;</span>
</pre></div>

<ul>
<li>Create the target topics in the target cluster. The following topics needs to be created upfront in events streams as Access Control does not authorize program to create topic dynamically.</li>
</ul>
<div class="codehilite"><pre><span></span>cloudctl es topic-create -n mm2-configs.source.internal -p 1 -r 3 -c cleanup.policy=compact
cloudctl es topic-create -n mm2-offsets.source.internal -p 25 -r 3 -c cleanup.policy=compact
cloudctl es topic-create -n mm2-status.source.internal -p 5 -r 3 -c cleanup.policy=compact
cloudctl es topic-create -n source.products -p 1 -r 3
cloudctl es topic-create -n source.heartbeats -p 1 -r 3
cloudctl es topic-create -n source.checkpoints.internal -p 1 -r 3 -c cleanup.policy=compact
</pre></div>

<ul>
<li>In one window terminal, start local cluster using docker-compose under the <code>mirror-maker-2/local-cluster</code> folder: <code>docker-compose up &amp;</code>. The data are persisted on the local disk in this folder. </li>
<li>If this is the first time you started the cluster, you need to create the <code>products</code> topic. Start a Kafka container to access the Kafka tool with the command:</li>
</ul>
<div class="codehilite"><pre><span></span>docker run -ti -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home --network kafkanet strimzi/kafka:latest-kafka-2.4.0 bash
</pre></div>

<p>Then in the bash shell, go to <code>/home/local-cluster</code> folder and execute the script: <code>./createProductsTopic.sh</code>. Verify it is created with the command: <code>/opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka1:9092 --list</code></p>
<ul>
<li>Send some products data to this topic. For that we use a docker python image. The docker file to build this image is <code>Dockerfile-python</code> so the command build this image (if you change the image name be sure to use the new name in future command): <code>docker build -f Dockerfile-python -t jbcodeforce/python37 .</code></li>
</ul>
<p>Once the image is built, start the python environment with the following commands:</p>
<p><div class="codehilite"><pre><span></span><span class="nb">source</span> ./setenv.sh
docker run -ti -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home --rm -e <span class="nv">KAFKA_BROKERS</span><span class="o">=</span><span class="nv">$KAFKA_SOURCE_BROKERS</span> --network kafkanet jbcodeforce/python37   bash
</pre></div>
  In the container bash shell do the following</p>
<div class="codehilite"><pre><span></span>$ <span class="nb">echo</span> <span class="nv">$KAFKA_BROKERS</span>
kafka1:9092,kafka2:9093,kafka3:9094
$ python SendProductToKafka.py 

<span class="o">[</span>KafkaProducer<span class="o">]</span> - <span class="o">{</span><span class="s1">&#39;bootstrap.servers&#39;</span>: <span class="s1">&#39;kafka1:9092,kafka2:9093,kafka3:9094&#39;</span>, <span class="s1">&#39;group.id&#39;</span>: <span class="s1">&#39;ProductsProducer&#39;</span><span class="o">}</span>
<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P01&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Carrots&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">4</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">1</span><span class="o">}</span>
<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P02&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Banana&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">6</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.6, <span class="s1">&#39;content_type&#39;</span>: <span class="m">2</span><span class="o">}</span>
<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P03&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Salad&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">4</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">1</span><span class="o">}</span>
<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P04&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Avocado&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">6</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">1</span><span class="o">}</span>
<span class="o">{</span><span class="s1">&#39;product_id&#39;</span>: <span class="s1">&#39;P05&#39;</span>, <span class="s1">&#39;description&#39;</span>: <span class="s1">&#39;Tomato&#39;</span>, <span class="s1">&#39;target_temperature&#39;</span>: <span class="m">4</span>, <span class="s1">&#39;target_humidity_level&#39;</span>: <span class="m">0</span>.4, <span class="s1">&#39;content_type&#39;</span>: <span class="m">2</span><span class="o">}</span>
<span class="o">[</span>KafkaProducer<span class="o">]</span> - Message delivered to products <span class="o">[</span><span class="m">0</span><span class="o">]</span>
<span class="o">[</span>KafkaProducer<span class="o">]</span> - Message delivered to products <span class="o">[</span><span class="m">0</span><span class="o">]</span>
<span class="o">[</span>KafkaProducer<span class="o">]</span> - Message delivered to products <span class="o">[</span><span class="m">0</span><span class="o">]</span>
<span class="o">[</span>KafkaProducer<span class="o">]</span> - Message delivered to products <span class="o">[</span><span class="m">0</span><span class="o">]</span>
<span class="o">[</span>KafkaProducer<span class="o">]</span> - Message delivered to products <span class="o">[</span><span class="m">0</span><span class="o">]</span>
</pre></div>

<ul>
<li>To validate the data are in the source topic we can use the console consumer. Here are the basic commands:</li>
</ul>
<div class="codehilite"><pre><span></span>docker run -ti -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home --network kafkanet strimzi/kafka:latest-kafka-2.4.0 bash
$ <span class="nb">cd</span> bin
$ ./kafka-console-consumer.sh --bootstrap-server kafka1:9092 --topic products --from-beginning
</pre></div>

<ul>
<li>Define the event streams properties file for the tool command. The <code>eventstream.properties</code> file looks like:</li>
</ul>
<div class="codehilite"><pre><span></span><span class="na">bootstrap.servers</span><span class="o">=</span><span class="s">broker-3-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-1-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-0-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-5-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-2-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-4-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093</span>
<span class="na">security.protocol</span><span class="o">=</span><span class="s">SASL_SSL</span>
<span class="na">ssl.protocol</span><span class="o">=</span><span class="s">TLSv1.2</span>
<span class="na">sasl.mechanism</span><span class="o">=</span><span class="s">PLAIN</span>
<span class="na">sasl.jaas.config</span><span class="o">=</span><span class="s">org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;token&quot; password=....;</span>
</pre></div>

<ul>
<li>Restart the <code>kafka-console-consumer</code> with the bootstrap URL to access to event streams and with the replicated topic: <code>source.products</code>. Use the previously created properties file to get authentication properties so the command looks like:</li>
</ul>
<div class="codehilite"><pre><span></span><span class="nb">source</span> /home/setenv.sh
./kafka-console-consumer.sh --bootstrap-server <span class="nv">$KAFKA_TARGET_BROKERS</span> --consumer.config /home/eventstream.properties --topic source.products --from-beginning
</pre></div>

<ul>
<li>Now we are ready to start Mirror Maker 2.0 in a local docker image:</li>
</ul>
<div class="codehilite"><pre><span></span>docker run -ti -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home --network kafkanet strimzi/kafka:latest-kafka-2.4.0 bash
$ /home/local-cluster/launchMM2.sh
</pre></div>

<p>The trace includes a ton of messages, which demonstrate different consumers and producers, workers and tasks. The logs can be found in the <code>/tmp/logs</code> folder. The table includes some of the elements of this configuration:</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Worker clientId=connect-2, groupId=target-mm2</td>
<td>Herder for target cluster topics but reading source topic</td>
</tr>
<tr>
<td>Producer clientId=producer-1</td>
<td>Producer to taget cluster</td>
</tr>
<tr>
<td>Consumer clientId=consumer-target-mm2-1, groupId=target-mm2]</td>
<td>Subscribed to 25 partition(s): mm2-offsets.target.internal-0 to 24</td>
</tr>
<tr>
<td>Consumer clientId=consumer-target-mm2-2, groupId=target-mm2]</td>
<td>Subscribed to 5 partition(s): mm2-status.target.internal-0 to 4</td>
</tr>
<tr>
<td>Consumer clientId=consumer-target-mm2-3, groupId=target-mm2]</td>
<td>Subscribed to partition(s): mm2-configs.target.internal-0</td>
</tr>
<tr>
<td>Worker clientId=connect-2, groupId=target-mm2 . Starting connectors and tasks using config offset 6.</td>
<td>This trace shows mirror maker will start to consume message from the offset 6. A previous run has already committed the offset for this client id. This illustrate a Mirror Maker restarts</td>
</tr>
<tr>
<td>Starting connector MirrorHeartbeatConnector and Starting task MirrorHeartbeatConnector-0</td>
<td></td>
</tr>
<tr>
<td>Starting connector MirrorCheckpointConnector</td>
<td></td>
</tr>
<tr>
<td>Starting connector MirrorSourceConnector</td>
<td></td>
</tr>
</tbody>
</table>
<p>As expected, in the consumer console we can see the 5 product messages arriving after replication.</p>
<h2 id="scenario-2-run-mirror-maker-2-cluster-close-to-target-cluster">Scenario 2: Run Mirror Maker 2 Cluster close to target cluster</h2>
<p>So the scenario is similar in term of test as the scenario 1 but Mirror Maker runs within an OpenShift cluster in the same data center as Event Streams cluster.</p>
<p><img alt="" src="../images/mm2-local-to-es.png" /></p>
<p>We have created an Event Streams cluster on Washington DC data center. We have a Strimzi Kafka cluster defined in Washington data center in a OpenShift Cluster. As both clusters are in the same data center, we deploy Mirror Maker 2.0 close to target cluster (Event Streams on Cloud).</p>
<p>What needs to be done:</p>
<ul>
<li>Get a Openshift cluster in the same data center as Event Streams service.</li>
<li>Create a project in OpenShift, for example: <code>MirrorMakerToES</code>.</li>
<li>Deploy the Strimzi Kafka cluster and topic operators. See the sections on role binding, cluster operator, topic operator and user operator deployments from the <a href="../strimzi-deploy/">deployment note</a>.</li>
<li>Define source and target cluster properties in mirror maker mm2.yaml file </li>
</ul>
<div class="codehilite"><pre><span></span>
</pre></div>

<ul>
<li>Deploy Mirror maker 2.0 pod within this project</li>
</ul>
<div class="codehilite"><pre><span></span>oc apply -f mm2-pod.yaml 
</pre></div>

<ul>
<li>Define a secret for the API key of the target cluster
<code>oc create secret generic es-apikey-target --from-literal=binding=am_</code></li>
<li>Start a producer (for example the below code send products reference data into products topic)</li>
</ul>
<div class="codehilite"><pre><span></span><span class="nb">export</span> <span class="nv">KAFKA_PWD</span><span class="o">=</span><span class="s2">&quot;replace-with-event-streams-apikey&quot;</span>
<span class="nb">export</span> <span class="nv">KAFKA_BROKERS</span><span class="o">=</span><span class="s2">&quot;...&quot;</span>
docker run -ti -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home --rm -e <span class="nv">KAFKA_PWD</span><span class="o">=</span><span class="nv">$KAFKA_PWD</span> -e <span class="nv">KAFKA_BROKERS</span><span class="o">=</span><span class="nv">$KAFKA_BROKERS</span> jbcodeforce/python37   bash
python SendProductToKafka.py
</pre></div>

<ul>
<li>Define a source cluster properties file with truststore and bootstrap servers. This file is used for the different Kafka tools like kafka-topics.sh or console producer and consumer.</li>
</ul>
<div class="codehilite"><pre><span></span><span class="na">bootstrap.servers</span><span class="o">=</span><span class="s">....</span>
<span class="na">security.protocol</span><span class="o">=</span><span class="s">SSL</span>
<span class="na">ssl.truststore.password</span><span class="o">=</span><span class="s">password</span>
<span class="na">ssl.truststore.location</span><span class="o">=</span><span class="s">/home/truststore.jks</span>
</pre></div>

<p>and a target cluster property file:</p>
<div class="codehilite"><pre><span></span><span class="na">bootstrap.servers</span><span class="o">=</span><span class="s">broker-3-q.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-4-q.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093</span>
<span class="na">security.protocol</span><span class="o">=</span><span class="s">SASL_SSL</span>
<span class="na">ssl.protocol</span><span class="o">=</span><span class="s">TLSv1.2</span>
<span class="na">sasl.mechanism</span><span class="o">=</span><span class="s">PLAIN</span>
<span class="na">sasl.jaas.config</span><span class="o">=</span><span class="s">org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;token&quot; password=&quot;am_...&quot;;</span>
</pre></div>

<ul>
<li>
<p>Start a product producer with a python client code</p>
</li>
<li>
<p>Start a consumer locally on your compute using the Strimzi/kafka image.</p>
</li>
</ul>
<div class="codehilite"><pre><span></span>docker run -ti -v $(pwd):/home strimzi/kafka:latest-kafka-2.4.0 bash
cd /opt/kafka/bin
./kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap-jb-kafka-strimzi.gse-eda-demos-fa9ee67c9ab6a7791435450358e564cc-0001.us-east.containers.appdomain.cloud:443 --consumer.config /home/strimzi.properties  --topic products
</pre></div>

<ul>
<li>Verify the created topics on target cluster (Event Streams)</li>
</ul>
<p><div class="codehilite"><pre><span></span>/opt/kafka/bin/kafka-topics.sh --bootstrap-server <span class="nv">$KAFKA_BROKERS</span> --command-config /home/eventstream.properties --list
</pre></div>
* In case you need it... looking at source cluster topic list:</p>
<div class="codehilite"><pre><span></span>/opt/kafka/bin/kafka-topics.sh --bootstrap-server my-cluster-kafka-bootstrap-jb-kafka-strimzi.gse-eda-demos-fa9ee67c9ab6a7791435450358e564cc-0001.us-east.containers.appdomain.cloud:443 --command-config /home/strinzi.properties --list 
</pre></div>

<p>Get detail on one topic:</p>
<div class="codehilite"><pre><span></span>/opt/kafka/bin//kafka-topics.sh --bootstrap-server my-cluster-kafka-bootstrap-jb-kafka-strimzi.gse-eda-demos-fa9ee67c9ab6a7791435450358e564cc-0001.us-east.containers.appdomain.cloud:443  --command-config /home/strimzi.properties --describe --topic products
</pre></div>

<h2 id="scenario-3-from-event-streams-to-local-cluster">Scenario 3: From Event Streams to local cluster</h2>
<p>For the first test the source is Event Streams on IBM Cloud and the target is a local server (may be on a laptop using Kafka strimzi images started with docker compose)</p>
<p><img alt="" src="../images/mm2-test2.png" /></p>
<p>This time the producer adds headers and message and Mirror maker need to get the APIkey, so the mirror-maker.properties looks like:</p>
<div class="codehilite"><pre><span></span><span class="na">clusters</span><span class="o">=</span><span class="s">source, target</span>
<span class="na">source.bootstrap.servers</span><span class="o">=</span><span class="s">broker-3-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-1-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-0-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-5-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-2-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093,broker-4-qnprtqnp7hnkssdz.kafka.svc01.us-east.eventstreams.cloud.ibm.com:9093</span>
<span class="na">source.security.protocol</span><span class="o">=</span><span class="s">SASL_SSL</span>
<span class="na">source.ssl.protocol</span><span class="o">=</span><span class="s">TLSv1.2</span>
<span class="na">source.sasl.mechanism</span><span class="o">=</span><span class="s">PLAIN</span>
<span class="na">source.sasl.jaas.config</span><span class="o">=</span><span class="s">org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;token&quot; password=&quot;985...&quot;;</span>
<span class="na">target.bootstrap.servers</span><span class="o">=</span><span class="s">kafka1:9092,kafka2:9093,kafka3:9094</span>
<span class="c"># enable and configure individual replication flows</span>
<span class="na">source-&gt;target.enabled</span><span class="o">=</span><span class="s">true</span>
<span class="na">source-&gt;target.topics</span><span class="o">=</span><span class="s">orders</span>
</pre></div>

<p>We have created an Event Streams cluster on Washington DC data center. We have a Strimzi Kafka cluster defined in Washington data center in a OpenShift Cluster. As both clusters are in the same data center, we deploy Mirror Maker 2.0 close to target cluster (Event Streams on Cloud).</p>
<h2 id="scenario-4-from-event-streams-on-cloud-to-strimzi-cluster-on-openshift">Scenario 4: From Event Streams On Cloud to Strimzi Cluster on Openshift</h2>
<h2 id="scenario-5-from-kafka-cluster-on-openshift-cluster-to-local-cluster">Scenario 5: From Kafka cluster on Openshift cluster to local cluster</h2>
<p><img alt="" src="../images/mm2-test1.png" /></p>
<p>The source cluster is a Strimzi cluster running on Openshift as a service on IBM Cloud. It was installed following the instructions <a href="https://ibm-cloud-architecture.github.io/refarch-eda/deployments/strimzi/deploy/">documented here</a>.</p>
<p>The target cluster is also based on Strimzi kafka 2.4 docker image, but run in a local host, with docker compose. It starts two zookeeper nodes, and three kafka nodes. We need 3 kafka brokers as mirror maker created topics with a replication factor set to 3.</p>
<ul>
<li>
<p>Start the target cluster runnning on your laptop using:</p>
<div class="codehilite"><pre><span></span>docker-compose up
</pre></div>

</li>
<li>
<p>Start <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0">mirror maker2.0</a>: </p>
<p>By using a new container, start another kakfa 2.4+ docker container, connected to the  brokers via the <code>kafkanet</code> network, and mounting the configuration in the <code>/home</code>:</p>
<div class="codehilite"><pre><span></span>docker run -ti --network kafkanet -v <span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/home strimzi/kafka:latest-kafka-2.4.0 bash
</pre></div>

<p>Inside this container starts mirror maker 2.0 using the script: <code>/opt/kakfa/bin/connect-mirror-maker.sh</code></p>
<div class="codehilite"><pre><span></span>/opt/kakfa/bin/connect-mirror-maker.sh /home/strimzi-mm2.properties
</pre></div>

<p>The <code>strimzi-mm2.properties</code> properties file given as argument defines the source and target clusters and the topics to replicate:</p>
<div class="codehilite"><pre><span></span><span class="na">clusters</span><span class="o">=</span><span class="s">source, target</span>
<span class="na">source.bootstrap.servers</span><span class="o">=</span><span class="s">my-cluster-kafka-bootstrap-jb-kafka-strimzi.gse-eda-demos-fa9ee67c9ab6a7791435450358e564cc-0001.us-east.containers.appdomain.cloud:443</span>
<span class="na">source.security.protocol</span><span class="o">=</span><span class="s">SSL</span>
<span class="na">source.ssl.truststore.password</span><span class="o">=</span><span class="s">password</span>
<span class="na">source.ssl.truststore.location</span><span class="o">=</span><span class="s">/home/truststore.jks</span>
<span class="na">target.bootstrap.servers</span><span class="o">=</span><span class="s">kafka1:9092,kafka2:9093,kafka3:9094</span>
<span class="c"># enable and configure individual replication flows</span>
<span class="na">source-&gt;target.enabled</span><span class="o">=</span><span class="s">true</span>
<span class="na">source-&gt;target.topics</span><span class="o">=</span><span class="s">orders</span>
</pre></div>

<p>As the source cluster is deployed on Openshift, the exposed route to access the brokers is using TLS connection. So we need the certificate and create a truststore to be used by those Java programs. All kafka tools are done in java or scala so running in a JVM, which needs truststore for keep trusted TLS certificates. 
When running from a remote system to get the certificate do the following steps:</p>
<ol>
<li>
<p>Get the host ip address from the Route resource</p>
<div class="codehilite"><pre><span></span>oc get routes my-cluster-kafka-bootstrap -o<span class="o">=</span><span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.status.ingress[0].host}{&quot;\n&quot;}&#39;</span>
</pre></div>

</li>
<li>
<p>Get the TLS certificate from the broker</p>
<div class="codehilite"><pre><span></span>oc get secrets
oc extract secret/my-cluster-cluster-ca-cert --keys<span class="o">=</span>ca.crt --to<span class="o">=</span>- &gt; ca.crt
</pre></div>

</li>
<li>
<p>Transform the certificate fo java truststore</p>
<div class="codehilite"><pre><span></span>keytool -import -trustcacerts -alias root -file ca.crt -keystore truststore.jks -storepass password -noprompt
</pre></div>

</li>
</ol>
<p>For Openshift or Kubernetes deployment, the mirror maker descriptor needs to declare the TLS stamza:</p>
<div class="codehilite"><pre><span></span><span class="nt">mirrors</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">sourceCluster</span><span class="p">:</span> <span class="s">&quot;my-cluster-source&quot;</span>
<span class="nt">targetCluster</span><span class="p">:</span> <span class="s">&quot;my-cluster-target&quot;</span>
<span class="nt">sourceConnector</span><span class="p">:</span>
  <span class="nt">config</span><span class="p">:</span>
    <span class="nt">replication.factor</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="nt">offset-syncs.topic.replication.factor</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="nt">sync.topic.acls.enabled</span><span class="p">:</span> <span class="s">&quot;false&quot;</span>
<span class="nt">targetConnector</span><span class="p">:</span>
  <span class="nt">tls</span><span class="p">:</span>
    <span class="nt">trustedCertificates</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">secretName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">my-cluster-cluster-cert</span>
        <span class="nt">certificate</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ca.crt</span>
</pre></div>

</li>
<li>
<p>The consumer may be started in second or third step. To start it, you can use a new container or use one of the running kafka broker container. Using the <code>Docker perspective</code> in Visual Code, we can get into a bash shell within one of the Kafka broker container. The local folder is mounted to <code>/home</code>. Then the script, <code>consumeFromLocal.sh source.orders</code> will get messages from the replicated topic: <code>source.orders</code></p>
</li>
<li>
<p>Finally start the producer in another kafka broker shell</p>
</li>
</ul>
<div class="codehilite"><pre><span></span>/home/produceToStrimzi.sh orders
</pre></div>

<h2 id="typical-errors-in-mirror-maker-2-traces">Typical errors in Mirror Maker 2 traces</h2>
<ul>
<li>Plugin class loader for connector: 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' was not found.</li>
<li>Error while fetching metadata with correlation id 2314 : {source.heartbeats=UNKNOWN_TOPIC_OR_PARTITION}:<ul>
<li>Those messages may come from multiple reasons. One is the name topic is not created. In Event Streams topics needs to be created via CLI or User Interface. It can also being related to the fact the consumer polls on a topic that has just been created and the leader for this topic-partition is not yet available, you are in the middle of a leadership election.</li>
<li>The advertised listener may not be set or found.</li>
</ul>
</li>
<li>Exception on not being able to create Log directory: do the following: <code>export LOG_DIR=/tmp/logs</code></li>
<li>ERROR WorkerSourceTask{id=MirrorSourceConnector-0} Failed to flush, timed out while waiting for producer to flush outstanding 1 messages</li>
<li>ERROR WorkerSourceTask{id=MirrorSourceConnector-0} Failed to commit offsets (org.apache.kafka.connect.runtime.SourceTaskOffsetCommitter:114)</li>
</ul>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../kstreams/" title="Kafka streaming notes" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Kafka streaming notes
              </span>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.b806dc00.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
  </body>
</html>